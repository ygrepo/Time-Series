{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS-GA 3001.001 Special Topics in Data Science: Probabilistic Time Series Analysis\n",
    "\n",
    "# Week 5 particle filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "from pykalman import KalmanFilter\n",
    "import time\n",
    "\n",
    "# Data Visualization\n",
    "def plot_kalman(time, latent, data, ky=None, ky_var=None, plot_type=\"r-\", label=None, title='sample'):\n",
    "    \"\"\"\n",
    "    Plot the trajectory\n",
    "    \"\"\"\n",
    "    x, y = time, latent\n",
    "    nx, ny = data[:, 0], data[:, 1]\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(18, 4))\n",
    "    if ky is not None:\n",
    "        ax[0].plot(x, y, 'g-', time, nx, 'b.', time, ny, 'b.', time, ky, 'r-', plot_type)\n",
    "        if ky_var is not None:\n",
    "            ax[0].fill_between(time, ky - np.sqrt(ky_var),\n",
    "                               ky + np.sqrt(ky_var), color='r', alpha=.5, label='estimate')\n",
    "        ax[0].legend()\n",
    "        ax[1].plot(y, ky, '.', color='grey')\n",
    "        ax[1].set_xlabel('real latent')\n",
    "        ax[1].set_ylabel('estimated latent')\n",
    "        ax[1].set_title('cc %.3f' %(np.corrcoef(y[:,0], ky)[0,1]))\n",
    "    else:\n",
    "        ax[0].plot(x, y, 'g-', x, nx, 'b.', x, ny, 'b.')\n",
    "\n",
    "        ax[1].plot(y, nx, '.k', label='observed dim 1')\n",
    "        ax[1].plot(y, ny, '.', color='grey', label='observed dim 2')\n",
    "        ax[1].set_xlabel('latent')\n",
    "        ax[1].set_ylabel('observed')\n",
    "        ax[1].legend()\n",
    "\n",
    "    ax[0].set_xlabel('time')\n",
    "    ax[0].set_ylabel('latent')\n",
    "    ax[0].set_title(title)\n",
    "    ax[1].set_aspect(1)\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def print_parameters(kf_model, need_params=None, evals=False):\n",
    "    \"\"\"\n",
    "    Function that prints out the parameters for a Kalman Filter\n",
    "    @param - kf_model : the model object\n",
    "    @param - need_params : a list of string\n",
    "    \"\"\"\n",
    "    if need_params is None:\n",
    "        need_params = ['transition_matrices', 'observation_matrices', 'transition_covariance', 'observation_covariance',\n",
    "                       'initial_state_mean', 'initial_state_covariance']\n",
    "    for param in need_params:\n",
    "        print(\"{0} = {1}, shape = {2}\\n\".format(param, getattr(kf_model, param), getattr(kf_model, param).shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example linear dynamical system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "# Sampling\n",
    "n_dim_state = 1\n",
    "n_dim_obs = 2\n",
    "tt = np.arange(200)\n",
    "kf_GT = KalmanFilter(n_dim_state=n_dim_state, n_dim_obs=n_dim_obs, \n",
    "                  transition_matrices = np.eye(n_dim_state)*.9, \n",
    "                  transition_covariance = np.eye(n_dim_state), \n",
    "                  observation_matrices = np.random.randn(n_dim_state*n_dim_obs).reshape(n_dim_obs, n_dim_state),\n",
    "                  observation_covariance = np.eye(n_dim_obs)*10,\n",
    "                  initial_state_mean = np.zeros(n_dim_state), \n",
    "                  initial_state_covariance = np.eye(n_dim_state))\n",
    "latent, data = kf_GT.sample(len(tt), initial_state=kf_GT.initial_state_mean, random_state=np.random.RandomState(0))\n",
    "#fig = plot_kalman(tt, latent, data, title='sample');\n",
    "#print_parameters(kf_GT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use KF to do inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_mean, filtered_cov = kf_GT.filter(data)\n",
    "smoothed_mean, smoothed_cov = kf_GT.smooth(data)\n",
    "\n",
    "fig = plot_kalman(tt, latent, data, ky = smoothed_mean[:,0], ky_var=smoothed_cov[:,0,0], title='kf');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Particle Filtering: alternative inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We know*: data and parameters (A, C, $\\Sigma$)\n",
    "\n",
    "*We assume*: linear transformation in latent space, linear mapping from latent to observed space, Gaussian observations\n",
    "\n",
    "<br>\n",
    "<img src='img/LDS.svg', width = 300, height=300>\n",
    "\n",
    "*We want*: approximation of the posterior marginals $P(z_n|x_{1:t})$\n",
    "\n",
    "*How*: generate samples of $P(z_n^{(i)}|z_{n-1})$ through particle filtering, reweigh by observations, and average to obtain expected value\n",
    "\n",
    "<br>\n",
    "<img src='img/PF_illustration.svg', width = 200, height=200>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) generate samples for $z_1$ \n",
    "\n",
    "1) draw $N_{samp}$ samples (=particles) given initial condition $z_0$\n",
    "$$z_1^{(i)}\\rvert z_0$$\n",
    "where $i=1, ..., N_{samp}$\n",
    "\n",
    "### B) weigh samples for $z_n^{(i)}$ given observational evidence from $x_n$\n",
    "\n",
    "2) compute the probability for the data for each sampled $z_n^{(i)}$: \n",
    "$$P(x_n|z_n^{(i)})$$\n",
    "\n",
    "3) compute the weights $w_n^{(i)}$ given $P(x_n|z_n^{(i)})$:\n",
    "$$w_n^{(i)}=\\frac{P(x_n|z_n^{(i)})}{\\sum_iP(x_n|z_n^{(i)})}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C) produce new samples at $n+1$\n",
    "\n",
    "4) draw $N_{samp}$ times from multinomial distribution with probabilities $w_n$, giving you class assignments $c_{(i)}$ that indicate which samples $z_n^{(i)}$ to use\n",
    "\n",
    "5) produce samples for $z_{n+1}^{(i)}$ from the samples $z_n^{(c_{(i)})}$\n",
    "\n",
    "6) keep going with step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# coding: implement the particle filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class myParticleFiltering:\n",
    "\n",
    "    def __init__(self, time, transition_matrices, transition_covariance, observation_matrices,\n",
    "                 observation_covariance, initial_state_mean, initial_state_covariance):\n",
    "        self.transition_matrices = transition_matrices\n",
    "        self.transition_covariance = transition_covariance\n",
    "        self.observation_matrices = observation_matrices\n",
    "        self.observation_covariance = observation_covariance\n",
    "        self.initial_state_mean = initial_state_mean\n",
    "        self.initial_state_covariance = initial_state_covariance\n",
    "        self.time = time\n",
    "        # placeholder\n",
    "        self.est_z_mean = np.zeros(len(time)) * np.nan\n",
    "        self.est_z_var = np.zeros(len(time)) * np.nan\n",
    "\n",
    "    def plot_particle_update(self, z_samp, w, Nbins=100, seed=0):\n",
    "        np.random.seed(seed)\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        htmp = np.histogram(z_samp, Nbins)\n",
    "        plt.fill_between(htmp[1][1:], np.zeros(Nbins), htmp[0], color='blue', alpha=.4, label='sample distribution')\n",
    "        plt.plot([self.initial_state_mean, self.initial_state_mean], [0, z_samp.shape[0]/Nbins], 'b-', label='initial mean')\n",
    "        # create new particles\n",
    "        k = np.random.multinomial(z_samp.shape[0], w)\n",
    "        htmp = np.histogram(np.repeat(z_samp, k), Nbins)\n",
    "        plt.fill_between(htmp[1][1:], np.zeros(Nbins), htmp[0], color='red', alpha=.4, label='reweighted sample distribution')\n",
    "        plt.plot([self.est_z_mean[0], self.est_z_mean[0]], [0, z_samp.shape[0]/Nbins], 'r-', label='mean of weighted samples')\n",
    "        plt.legend()\n",
    "        plt.xlabel('latent $z_n^{(i)}$')\n",
    "        plt.ylabel('counts')\n",
    "\n",
    "    def particle_filter(self, data, Nsamp, seed=0):\n",
    "        ###############################################\n",
    "        # TODO: implementation of the particle filter #\n",
    "        ###############################################\n",
    "        np.random.seed(seed)\n",
    "        # initial conditions:\n",
    "        self.est_z_mean[0] = self.initial_state_mean.copy()\n",
    "        self.est_z_var[0] = self.initial_state_covariance.copy()\n",
    "\n",
    "        # placeholder\n",
    "        self.z_samp = np.zeros([Nsamp, len(self.time)])\n",
    "        self.w = np.zeros([Nsamp, len(self.time)])\n",
    "        \n",
    "        ### create samples from distribution with initial conditions\n",
    "        # TODO: your code here!\n",
    "        z_samp_new = np.repeat(0, Nsamp) \n",
    "        \n",
    "        for nn in range(len(self.time)):\n",
    "\n",
    "            ### create samples for next time step using the particles\n",
    "            # TODO: your code here:\n",
    "            z_samp = np.zeros(Nsamp)\n",
    "\n",
    "            ### compute the weights (implement function below)\n",
    "            w = self.compute_w(data[nn, :], z_samp)\n",
    "            \n",
    "            # save particles and weights\n",
    "            self.z_samp[:, nn] = z_samp\n",
    "            self.w[:, nn] = w\n",
    "\n",
    "            ### keep track of mean and variance of the weighted samples\n",
    "            # TODO: your code here:\n",
    "            self.est_z_mean[nn] = 0\n",
    "            self.est_z_var[nn] = 1\n",
    "\n",
    "            ### compute class assignments\n",
    "            # TODO: your code here:\n",
    "            k = np.ones(Nsamp)\n",
    "            \n",
    "            ### create new particles\n",
    "            # TODO: your code here:\n",
    "            z_samp_new = np.zeros(Nsamp)\n",
    "\n",
    "    def compute_w(self, data_nn, z_samp, seed=0):\n",
    "        np.random.seed(seed)\n",
    "        ###############################################\n",
    "        ####### function to compute weights ###########\n",
    "        ###############################################\n",
    "        # TODO: your code here:\n",
    "        \n",
    "        \n",
    "        \n",
    "        return np.ones(z_samp.shape[0])/z_samp.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# create particle filter class with true parameters\n",
    "pf = myParticleFiltering(tt, kf_GT.transition_matrices[0], kf_GT.transition_covariance,\n",
    "                         kf_GT.observation_matrices, kf_GT.observation_covariance, \n",
    "                         kf_GT.initial_state_mean, kf_GT.initial_state_covariance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run the particle filter with 100 particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "pf.particle_filter(data, Nsamp=1000, seed=1)\n",
    "end = time.time()\n",
    "print('time required for particle filter: ', np.round(end-start,3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### look at an example distribution of samples and their corresponding reweighted samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.plot_particle_update(pf.z_samp[:,0], pf.w[:,0],Nbins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### should look something like this ...\n",
    "\n",
    "<br>\n",
    "<img src='img/PF_update.svg', width =  500, height=500>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### particle-filter estimated latent trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_kalman(tt, latent, data, ky = pf.est_z_mean, ky_var=pf.est_z_var, title='particle filtering');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### should look something like this ...\n",
    "\n",
    "<br>\n",
    "<img src='img/PF_1000.svg', width = 1000, height=1000>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### decrease the number of particles you produce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "pf.particle_filter(data, Nsamp=10, seed=1)\n",
    "end = time.time()\n",
    "print('time required for particle filter: ', np.round(end-start,3), ' sec')\n",
    "fig = plot_kalman(tt, latent, data, ky = pf.est_z_mean, ky_var=pf.est_z_var, title='particle filtering');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### should look something like this ...\n",
    "\n",
    "<br>\n",
    "<img src='img/PF_10.svg', width = 1000, height=1000>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### increase the number of particles you produce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "pf.particle_filter(data, Nsamp=10000, seed=1)\n",
    "end = time.time()\n",
    "print('time required for particle filter: ', np.round(end-start,3))\n",
    "fig = plot_kalman(tt, latent, data, ky = pf.est_z_mean, ky_var=pf.est_z_var, title='particle filtering');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### should look something like this ...\n",
    "\n",
    "<br>\n",
    "<img src='img/PF_10000.svg', width = 1000, height=1000>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please turn in the code as a notebook AND as a pdf before 10/16/2019 3:00 pm. Please name your notebook netid.ipynb.\n",
    "\n",
    "### Your work will be evaluated based on the code and plots. You don't need to write down your answers to these questions in the text blocks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
